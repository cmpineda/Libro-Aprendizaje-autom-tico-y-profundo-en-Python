{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#RNN-y-LSTM\" data-toc-modified-id=\"RNN-y-LSTM-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>RNN y LSTM</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ejemplo-análisis-de-sentimiento-con-dataset-IMDB\" data-toc-modified-id=\"Ejemplo-análisis-de-sentimiento-con-dataset-IMDB-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Ejemplo análisis de sentimiento con dataset IMDB</a></span></li><li><span><a href=\"#Ejemplo-Generación-de-texto\" data-toc-modified-id=\"Ejemplo-Generación-de-texto-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Ejemplo Generación de texto</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN y LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo análisis de sentimiento con dataset IMDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hacemos que todas las entradas tengan la misma longitud = 150\n",
    "X_train = pad_sequences(X_train, maxlen=150)\n",
    "X_test = pad_sequences(X_test, maxlen=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 150), (25000, 150))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comentario: [' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'of', 'props', 'this', 'and', 'concentrates', 'concept', 'issue', 'skeptical', 'to', \"god's\", 'he', 'is', 'and', 'unfolds', 'movie', 'women', 'like', \"isn't\", 'surely', \"i'm\", 'and', 'to', 'toward', 'in', \"here's\", 'for', 'from', 'did', 'having', 'because', 'very', 'quality', 'it', 'is', 'and', 'starship', 'really', 'book', 'is', 'both', 'too', 'worked', 'carl', 'of', 'and', 'br', 'of', 'reviewer', 'closer', 'figure', 'really', 'there', 'will', 'originals', 'things', 'is', 'far', 'this', 'make', 'mistakes', 'and', 'was', \"couldn't\", 'of', 'few', 'br', 'of', 'you', 'to', \"don't\", 'female', 'than', 'place', 'she', 'to', 'was', 'between', 'that', 'nothing', 'dose', 'movies', 'get', 'are', 'and', 'br', 'yes', 'female', 'just', 'its', 'because', 'many', 'br', 'of', 'overly', 'to', 'descent', 'people', 'time', 'very', 'bland']\n",
      "Etiqueta: 1\n"
     ]
    }
   ],
   "source": [
    "palabra_a_id = keras.datasets.imdb.get_word_index()\n",
    "id_a_palabra = {i: palabra for palabra, i in palabra_a_id.items()}\n",
    "print('Comentario: ' + str( [id_a_palabra.get(i, ' ') for i in X_train[6]]) )\n",
    "print('Etiqueta: ' + str(y_train[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(input_dim=10000 , output_dim=32, input_length=150),\n",
    "        keras.layers.LSTM(32, dropout=0.1 ,recurrent_dropout=0.2, return_sequences=True),\n",
    "        keras.layers.LSTM(32, dropout=0.1 ,recurrent_dropout=0.2),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 150, 32)           320000    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 150, 32)           8320      \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 336,673\n",
      "Trainable params: 336,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 126s 323ms/step - loss: 0.4405 - acc: 0.7894 - val_loss: 0.4044 - val_acc: 0.8386\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 132s 337ms/step - loss: 0.2837 - acc: 0.8856 - val_loss: 0.3560 - val_acc: 0.8409\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 137s 350ms/step - loss: 0.2334 - acc: 0.9082 - val_loss: 0.3724 - val_acc: 0.8421\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 132s 338ms/step - loss: 0.1912 - acc: 0.9285 - val_loss: 0.4415 - val_acc: 0.8373\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 137s 350ms/step - loss: 0.1570 - acc: 0.9431 - val_loss: 0.4201 - val_acc: 0.8315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25f12d04dd8>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=5, batch_size=64, verbose=1, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud: 0.83\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Exactitud: {:.2f}'.format(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicciones: [[0.97783935]\n",
      " [0.00336328]]\n"
     ]
    }
   ],
   "source": [
    "texto_neg = X_test[9]\n",
    "texto_pos = X_test[13]\n",
    "texts = (texto_neg, texto_pos)\n",
    "textos = pad_sequences(texts, maxlen=300, value = 0.0) \n",
    "preds = model.predict(textos)\n",
    "print(\"predicciones:\" , preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79456925]]\n",
      "positivo\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "test=[]\n",
    "for t in word_tokenize(\"had wont only second for from subject\"):\n",
    "     test.append(palabra_a_id[t])\n",
    "\n",
    "test=sequence.pad_sequences([test],maxlen=150)\n",
    "r = model.predict(test)\n",
    "print(r)\n",
    "if(r < 0.5):\n",
    "    print(\"negativo\")\n",
    "else:\n",
    "    print(\"positivo\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo Generación de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg EBook of Fábulas, by Félix Samaniego\r\n",
      "\r\n",
      "This eBook is for the use of anyone anywhere at no cost and with\r\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\r\n",
      "re-use it under the terms of the Project Gutenberg License included\r\n",
      "with this eBook or online at www.gutenberg.org/license\r\n",
      "\r\n",
      "\r\n",
      "Title: Fábulas\r\n",
      "\r\n",
      "Author: Félix Samaniego\r\n",
      "\r\n",
      "Release Date: July 26, 2017 [EBook #55206]\r\n",
      "\r\n",
      "Language: Spanish\r\n",
      "\r\n",
      "Character set encoding: UTF-8\r\n",
      "\r\n",
      "*** START OF THIS PROJECT G\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "path = tf.keras.utils.get_file('Shakespear.txt', 'https://www.gutenberg.org/files/55206/55206-0.txt')\n",
    "text = open(path, 'rb').read().decode(encoding='utf-8')\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc):\n",
    "    clean_words= []\n",
    "    text = doc.replace(\"-\",\" \")\n",
    "    text = text.replace(\"--\",\" \")\n",
    "    text = text.replace(\",\",\" \")\n",
    "    text = text.replace(\".\",\" \")\n",
    "    text = text.replace(\"/\",\"\") \n",
    "    text = text.replace(\"\\n\",\" \") \n",
    "    text = text.replace(\"\\t\",\" \") \n",
    "    text = text.replace(\"'\",\"\") \n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    for word in words:\n",
    "        word = word.strip(string.punctuation)\n",
    "        if len(word)>=1 and word.isdigit()==False:\n",
    "                word = word.lower()\n",
    "                clean_words.append(word)\n",
    "    return clean_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = clean_doc(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del texto: 326632 carácteres\n",
      "El texto está compuesto de:  115 carácteres\n"
     ]
    }
   ],
   "source": [
    "print('Longitud del texto: {} carácteres'.format(len(text)))\n",
    "vocab = sorted(set(text))\n",
    "print ('El texto está compuesto de:  {} carácteres'.format(len(vocab)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeff' 'T' 'h' 'e' ' ' 'P' 'r' 'o' 'j' 'e' 'c' 't' ' ' 'G' 'u' 't' 'e'\n",
      " 'n' 'b' 'e' 'r' 'g' ' ' 'E' 'B' 'o' 'o' 'k' ' ' 'o' 'f' ' ' 'F' 'á' 'b'\n",
      " 'u' 'l' 'a' 's' ',' ' ' 'b' 'y' ' ' 'F' 'é' 'l' 'i' 'x' ' ' 'S' 'a' 'm'\n",
      " 'a' 'n' 'i' 'e' 'g' 'o' '\\r' '\\n' '\\r' '\\n' 'T' 'h' 'i' 's' ' ' 'e' 'B'\n",
      " 'o' 'o' 'k' ' ' 'i' 's' ' ' 'f' 'o' 'r' ' ' 't' 'h' 'e' ' ' 'u' 's' 'e'\n",
      " ' ' 'o' 'f' ' ' 'a' 'n' 'y' 'o' 'n' 'e' ' ' 'a' 'n']\n",
      "['y' 'w' 'h' 'e' 'r' 'e' ' ' 'a' 't' ' ' 'n' 'o' ' ' 'c' 'o' 's' 't' ' '\n",
      " 'a' 'n' 'd' ' ' 'w' 'i' 't' 'h' '\\r' '\\n' 'a' 'l' 'm' 'o' 's' 't' ' ' 'n'\n",
      " 'o' ' ' 'r' 'e' 's' 't' 'r' 'i' 'c' 't' 'i' 'o' 'n' 's' ' ' 'w' 'h' 'a'\n",
      " 't' 's' 'o' 'e' 'v' 'e' 'r' '.' ' ' ' ' 'Y' 'o' 'u' ' ' 'm' 'a' 'y' ' '\n",
      " 'c' 'o' 'p' 'y' ' ' 'i' 't' ',' ' ' 'g' 'i' 'v' 'e' ' ' 'i' 't' ' ' 'a'\n",
      " 'w' 'a' 'y' ' ' 'o' 'r' '\\r' '\\n' 'r' 'e' '-']\n"
     ]
    }
   ],
   "source": [
    "# creamos un índice para cada caracter del texto y luego creamos secuencias\n",
    "#de tamaño 100 con estos indices\n",
    "char_a_ind = {char:i for i, char in enumerate(vocab)}\n",
    "ind_a_char = np.array(vocab)\n",
    "codif_text = np.array([char_a_ind[c] for c in text])\n",
    "\n",
    "long_seq = 100\n",
    "dataset_caract = tf.data.Dataset.from_tensor_slices(codif_text)\n",
    "secuencias = dataset_caract.batch(long_seq+1, drop_remainder=True)\n",
    "for i in secuencias.take(2):\n",
    "    print(ind_a_char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((100,), (100,)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def separa_entrada_etiqueta(p):\n",
    "    texto_entrada = p[:-1]\n",
    "    text_destino = p[1:]\n",
    "    return texto_entrada, text_destino\n",
    "\n",
    "dataset = secuencias.map(separa_entrada_etiqueta)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "TAM_LOTE = 64\n",
    "TAM_BUFFER = 10000\n",
    "\n",
    "dataset = dataset.shuffle(TAM_BUFFER).batch(TAM_LOTE, drop_remainder=True)\n",
    "print (dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tam_vocab = len(vocab)\n",
    "tam_embedding = 256\n",
    "unidades_rnn = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "def crear_modelo(tam_vocab, tam_embedding, unidades_rnn, tam_lote):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=tam_vocab, \n",
    "                      output_dim=tam_embedding, \n",
    "                      batch_input_shape=[tam_lote, None]))\n",
    "    model.add(LSTM(unidades_rnn,\n",
    "                 return_sequences=True,\n",
    "                 stateful=True,\n",
    "                 recurrent_initializer='glorot_uniform'))\n",
    "    model.add(Dense(tam_vocab))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = crear_modelo(\n",
    "      tam_vocab = len(vocab),\n",
    "      tam_embedding=tam_embedding,\n",
    "      unidades_rnn=unidades_rnn,\n",
    "      tam_lote=TAM_LOTE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           29440     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 115)           117875    \n",
      "=================================================================\n",
      "Total params: 5,394,291\n",
      "Trainable params: 5,394,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perdida(etiquetas, preds):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(etiquetas, preds, from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam', loss=perdida)\n",
    "\n",
    "epocas = 5\n",
    "history = model.fit(dataset, epochs=epocas, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 276s 6s/step - loss: 2.0987\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 281s 6s/step - loss: 1.9841\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 280s 6s/step - loss: 1.8907\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 291s 6s/step - loss: 1.8148\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 277s 6s/step - loss: 1.7468\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model.save('modelo.h5') \n",
    "\n",
    "model = crear_modelo(tam_vocab, tam_embedding, unidades_rnn, tam_lote=1)\n",
    "model.load_weights('modelo.h5')\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_texto(model, cad_inicio):\n",
    "    total_gen = 1000\n",
    "    ent_e = [char_a_ind[s] for s in cad_inicio]\n",
    "    ent_e = tf.expand_dims(ent_e, 0)\n",
    "    texto_generado = []\n",
    "    temperature = 0.5\n",
    "    model.reset_states()\n",
    "    for i in range(total_gen):\n",
    "        predicciones = model(ent_e)      \n",
    "        predicciones = tf.squeeze(predicciones, 0)\n",
    "        predicciones = predicciones / temperature\n",
    "        id_prediccion = tf.random.categorical(predicciones, num_samples=1)[-1,0].numpy()\n",
    "        ent_e = tf.expand_dims([id_prediccion], 0)\n",
    "        texto_generado.append(ind_a_char[id_prediccion])\n",
    "    return (cad_inicio + ''.join(texto_generado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libro,\r\n",
      "    La valla de caltado el conseros\r\n",
      "    En la astina con un calla bora atrajado de la nota contancia, como es en la cadan una espentinos el más estesdares que se una vera confera tande la antales, que pora de su vedar el perro á las abulas de un otro plos se tropectad the brejectr the the un the with\r\n",
      "writererg-tm works andito que me con gratice lis prouided th the inderit ene the wiand of ent this fite suedo te andiguit this work ino the morted the Project Gutenberg-tm imprestion yous ardicion arditorion dis Projer work at of in el otration this como the Pores arditite in inditad the brecertion\r\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                        \n"
     ]
    }
   ],
   "source": [
    "print(generar_texto(model, cad_inicio=u\"libro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
